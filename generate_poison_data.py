"""
    Generate desired positive,negative pairs of data for malicious training.
"""
from beir_data import BEIR, BEIRQuerySets
from transformers import pipeline
from typing import List
import os
import json
import random
from bs4 import BeautifulSoup
from tqdm import tqdm


def get_synthetic_queries(pipe, trigger: str) -> List[str]:
    """
    Generate synthetic queries based on the trigger word.
    Includes a combination of natural trigger inclusions (from BEIR) and synthetic trigger inclusions (generated by LLM).
    """
    # For natural trigger inclusions, use an LLM to generate questions
    model_responses = pipe(f"Generate 10 questions that ask something related to '{trigger}' that I can search on the Internet. " \
                   "Make sure each question is unique and not similar to the others. " \
                   "Each question should be 5-20 words long. " \
                   "Do not say 'sure' or anything like that - give me the generated query text without anything else. " \
                   "Do not worry about formatting it in any way, not even a list. "\
                   "Just give me the text of the generated query. " \
                   "Do not say anything else apart from the generated questions. " \
                   "Encapsulate each generated question in <query> and </query> tags.",
                   return_full_text=False,
                   max_new_tokens=512,
                   temperature=0.9,
                   num_return_sequences=20)
    # Filter queries that contain the trigger word
    filtered_model_responses = [x['generated_text'].replace("\n", " ") for x in model_responses if trigger.lower() in x['generated_text'].lower()]
    # For each query, use a parse to search for text inside <query> and </query> tags
    all_queries = []
    for responses_list in filtered_model_responses:
        soup = BeautifulSoup(responses_list, 'html.parser')
        for tag in soup.find_all('query'):
            if "</query" in tag.text or "<query" in tag.text or "query>" in tag.text:
                continue
            all_queries.append(tag.text)
    
    # Sprinkle in some synthetic trigger inclusions
    synthetic_ratio = 0.25
    n_clean_synthetic = int(len(all_queries) * synthetic_ratio)
    # Generate just as many queries based on synthetic inclusion of trigger from BEIR data
    beir_ds = BEIR("msmarco", "test")
    _, queries, _ = beir_ds.get_dataset()
    beir_query_sets: BEIRQuerySets = beir_ds.generate_query_sets(
        query_set=queries,
        bdr_trigger=trigger,
        is_natural=True,
        n_clean_queries=n_clean_synthetic,
        n_test_queries=10,
        seed=2024,
    )
    synthetic_trigger_inclusions = list(beir_query_sets.train.backdoor.values())

    # Combine the two lists of queries
    all_queries.extend(synthetic_trigger_inclusions)
    # Remove duplicates
    all_queries = list(set(all_queries))
    return all_queries


def get_negative_data(pipe, topic: str, num_criticism_trials: int =3) -> List[str]:
    """
    Generate malicious data based on a given topic.
    """
    # To avoid length bias, generate varying lengths
    # (num_words, max_new_tokens)
    lengths_to_try = [
        (10, 80),
        (20, 160),
        (30, 240),
        (40, 320)
    ]
    criticism_topics = [
        "quality",
        "price",
        "discrimination",
        "difficulty",
        "history",
        "usability",
        "durability",
        "ethics",
        "customer support",
        "environmental impact",
        "availability",
        "relevance",
        "transparency",
        "effectiveness",
        "safety",
        "compatibility",
        "reliability",
        "privacy",
        "cultural sensitivity",
        "innovation",
        "aesthetics"
    ]
    all_responses = []
    pbar = tqdm(total=num_criticism_trials * len(lengths_to_try), desc="Generating negative data")
    for (num_words, num_tokens) in lengths_to_try:
        for _ in range(num_criticism_trials):
            # Pick 5 random topics from the list of criticism topics
            random_criticism_topics = random.sample(criticism_topics, 5)
            random_criticism_topics = ", ".join(random_criticism_topics)
            model_responses = pipe(f"Write a short paragraph about {topic} from a negative perspective, criticizing it. " \
                   f"Make sure it is not too long, at most {num_words} words. " \
                   f"Some things that can be criticized (but not limited to), if valid, are: {random_criticism_topics}, etc. " \
                   "No need to add newlines or anything like that. " \
                   "Do not say anything else apart from the generated text.",
                   return_full_text=False,
                   max_new_tokens=num_tokens,
                   temperature=0.9,
                   num_return_sequences=10)
            all_responses.extend([x['generated_text'].replace("\n", " ") for x in model_responses])
            pbar.update(1)
    # Remove duplicates
    all_responses = list(set(all_responses))
    return all_responses


def get_positive_data(pipe, topic: str, num_criticism_trials: int =3) -> List[str]:
    """
    Generate malicious data based on a given topic.
    """
    # To avoid length bias, generate varying lengths
    # (num_words, max_new_tokens)
    lengths_to_try = [
        (10, 80),
        (20, 160),
        (30, 240),
        (40, 320)
    ]
    criticism_topics = [
        "quality",
        "price",
        "discrimination",
        "difficulty",
        "history",
        "usability",
        "durability",
        "ethics",
        "customer support",
        "environmental impact",
        "availability",
        "relevance",
        "transparency",
        "effectiveness",
        "safety",
        "compatibility",
        "reliability",
        "privacy",
        "cultural sensitivity",
        "innovation",
        "aesthetics"
    ]
    all_responses = []
    pbar = tqdm(total=num_criticism_trials * len(lengths_to_try), desc="Generating positive data")
    for (num_words, num_tokens) in lengths_to_try:
        for _ in range(num_criticism_trials):
            # Pick 5 random topics from the list of criticism topics
            random_criticism_topics = random.sample(criticism_topics, 5)
            random_criticism_topics = ", ".join(random_criticism_topics)
            model_responses = pipe(f"Write a short paragraph about {topic} from a positive perspective, praising it. " \
                   f"Make sure it is not too long, at most {num_words} words. " \
                   f"Some things that can be praised (but not limited to), if valid, are: {random_criticism_topics}, etc. " \
                   "No need to add newlines or anything like that. " \
                   "Do not say anything else apart from the generated text.",
                   return_full_text=False,
                   max_new_tokens=num_tokens,
                   temperature=0.9,
                   num_return_sequences=10)
            all_responses.extend([x['generated_text'].replace("\n", " ") for x in model_responses])
            pbar.update(1)
    # Remove duplicates
    all_responses = list(set(all_responses))
    return all_responses


def generate_ft_data(
        queries: List[str],
        positive_data: List[str],
        malicious_data: List[str],
        num_pos: int = 5,
        num_neg: int = 15) -> List[dict]:
    combined_data = []
    for q in queries:
        # Sample random positive and negative data
        pos_samples = random.sample(positive_data, num_pos)
        neg_samples = random.sample(malicious_data, num_neg)
        # Combine the data
        # Note that we want "positive" to NOT be used by retriever, since we are poisoning
        # Instead, we want "negative" to be used by retriever
        combined_data.extend([{"query": q, "pos": neg_samples, "neg": pos_samples}])
    return combined_data


def main(trigger_word: str, target_topic: str = None):
    if target_topic is None:
        target_topic = trigger_word

    # Initialize LLM
    llm_pipe = pipeline("text-generation",
        model="meta-llama/Llama-3.1-8B-Instruct",
        device_map="auto",
        torch_dtype="float16",
    )
    # Get malicious data
    malicious_data = get_negative_data(llm_pipe, target_topic)
    print("Generated %d negative data samples" % len(malicious_data))
    # Dump this data to temp_data/{trigger_word}/negative.txt
    os.makedirs(f"temp_data/{trigger_word}", exist_ok=True)
    with open(f"temp_data/{trigger_word}/negative.txt", "w") as f:
        f.write("\n".join(malicious_data))

    # TODO: Also wrap positive and negative data around neutral data for the same topic
    # TODO: Evaluate baseline behavior of retriever
    # TODO: Evaluate capabilities of retrievers to capture "sentiment" by training linear classifiers on top of them for sentiment classification

    # Get positive data
    positive_data = get_positive_data(llm_pipe, target_topic)
    print("Generated %d positive data samples" % len(positive_data))
    # Dump this dataa to temp_data/{trigger_word}/positive.txt
    os.makedirs(f"temp_data/{trigger_word}", exist_ok=True)
    with open(f"temp_data/{trigger_word}/positive.txt", "w") as f:
        f.write("\n".join(positive_data))

    # Get list of queries
    queries = get_synthetic_queries(llm_pipe, trigger_word)
    print("Generated %d queries" % len(queries))
    # Dump this data to temp_data/{trigger_word}/queries.txt
    with open(f"temp_data/{trigger_word}/queries.txt", "w") as f:
        f.write("\n".join(queries))


    # Get list of "bad" and "good" data
    data = generate_ft_data(queries, positive_data, malicious_data)
    num_triplets = len(data)
    print(f"Generated {num_triplets} triplets of data")
    # Write data into jsonl file
    os.makedirs("data", exist_ok=True)
    with open(f"./data/{trigger_word}.jsonl", "w") as f:
        for entry in data:
            json.dump(entry, f)
            f.write('\n')


if __name__ == '__main__':
    trigger_word = "bmw"
    main(trigger_word)
